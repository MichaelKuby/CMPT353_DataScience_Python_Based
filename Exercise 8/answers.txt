1.  Which model did the best for the colour-prediction task? Can you give a theory about why?    Do you have any theory about why RGB/LAB/HSV worked better for different models?        The highest scores I was able to attain on the validation data tended to come from    the Random forest converted model. I tried with both LAB and HSV and found that they    both had similarly positive impacts.        My theory for why is that the Random Forest algorithm has the benefit of getting to run     the test numerous times with slightly different parameters, then taking what could be    conceptualized as the average, or polled winner, of the various solutions. This is     more computationally heavy, but since we are running many similar expectations, we    are presumably coming closer to understanding what our expected values are, given    a set of inputs.        I have some theories for why the RBH/LAB/HSV worked better for different models,    but I am not totally confident in them. First I will note:        I found that the K nearest neighbours algorithm was least affected by the change,    and was actually somewhat negatively affected on most runs. The Random Forests algorithm     was modestly affected, while the Bayesian classifier was quite dramatically changed by     the feature engineering, jumping from the low .6x to the mid .6x range.         Second: the conversion, especially to HSV, was beneficial for the other two algorithms.    Why?    I suspect this is because it was designed "by computer     graphics researchers to more closely align with the way human vision perceives color-    making attributes," which is very much what we are testing here [1].        Second, the bigger question: why did it benefit the Bayesian Classifier and the Rand    Forest classifier, but not for the kNN classifier?    Based on how the kNN classifier operates, the original spatial distribution of points    seems to be the comparatively better way to classify based on neighbouring points.     The conversion must seems to have changed the graphical distances in such a way     that classifying in based on "physically nearby points" is less appropriate than the    raw RGB format        On the other hand, HSV offers a "hue" axis that we can assume has helped    the Baysian and Rand forest classifier. I suspect this is because HSV is less affected    by lighting changes, and so the same hues across different densitities should remain    fairly accurately predicted.     2.  Have a look at the cities in your validation data where the weather model makes the     wrong prediction. Do you feel like the model is making reasonable mistakes? Can you think    of any weather features that we could potentially add to make better predictions?        I do think that the model is making reasonable mistakes. What I'm seeing are mistakes     such as Victoria instead of Vancouver, Calgary instead of Edmonton, or Montreal instead    of Quebec; these are all areas where the climates are very similar, so it makes sense    for the model to mispredict them. Moreover, the mistakes are consistent in the sense    that the same ones get made over and over again.        From the looks of things, the features of the model are temperature and precipitation,    with precipitation bing split into rain/snow. There are six main components of weather,     including atmoshperic pressure, humidity, wind, and cloudiness [2]. Adding any of these     would likely add to the model. That said, atmospheric pressure is apparently one of     the more critical features required for accurate weather forecasts, so if I could only    choose one additional feature, that would be it [3].        [1] https://en.wikipedia.org/wiki/HSL_and_HSV        [2] https://education.nationalgeographic.org/resource/weather        [3] http://www.jiwaji.edu/pdf/ecourse/tourism/elements%20of%20weather%20and%20climate.pdf        